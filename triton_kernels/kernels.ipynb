{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebed0f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ca28d",
   "metadata": {},
   "source": [
    "# Weighted Sum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491ee45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_fwd(\n",
    "    x_ptr, weight_ptr,            # Input pointers\n",
    "    output_ptr,                   # Output pointer\n",
    "    x_stride_row, x_stride_dim,   # Strides for x tensor\n",
    "    weight_stride_dim,           # Likely 1\n",
    "    output_stride_row,           # Likely 1\n",
    "    ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr,  # Tile shapes\n",
    "):\n",
    "    # Compute the index of the row tile this program instance will handle\n",
    "    row_tile_idx = tl.program_id(0)\n",
    "\n",
    "    # Create block pointers for inputs and output\n",
    "    x_block_ptr = tl.make_block_ptr(\n",
    "        x_ptr,\n",
    "        shape=(ROWS, D),\n",
    "        strides=(x_stride_row, x_stride_dim),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),\n",
    "        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    weight_block_ptr = tl.make_block_ptr(\n",
    "        weight_ptr,\n",
    "        shape=(D,),\n",
    "        strides=(weight_stride_dim,),\n",
    "        offsets=(0,),\n",
    "        block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "\n",
    "    output_block_ptr = tl.make_block_ptr(\n",
    "        output_ptr,\n",
    "        shape=(ROWS,),\n",
    "        strides=(output_stride_row,),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE,),\n",
    "        block_shape=(ROWS_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "\n",
    "    # Initialize output buffer\n",
    "    output = tl.zeros((ROWS_TILE_SIZE,), dtype=tl.float32)\n",
    "\n",
    "    for i in range(tl.cdiv(D, D_TILE_SIZE)):\n",
    "        row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option=\"zero\")\n",
    "        weight = tl.load(weight_block_ptr, boundary_check=(0,), padding_option=\"zero\")\n",
    "        output += tl.sum(row * weight[None, :], axis=1)\n",
    "\n",
    "        # Advance block pointers\n",
    "        x_block_ptr = x_block_ptr.advance((0, D_TILE_SIZE))\n",
    "        weight_block_ptr = weight_block_ptr.advance((D_TILE_SIZE,))\n",
    "\n",
    "    # Store the result\n",
    "    tl.store(output_block_ptr, output, boundary_check=(0,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a9bdb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WeightedSumFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight):\n",
    "        D, output_dims = x.shape[-1], x.shape[:-1]\n",
    "\n",
    "        # Reshape input tensor to 2D\n",
    "        input_shape = x.shape\n",
    "        x = rearrange(x, \"... d -> (...) d\")\n",
    "\n",
    "        ctx.save_for_backward(x, weight)\n",
    "\n",
    "        assert len(weight.shape) == 1 and weight.shape[0] == D, \"Dimension mismatch\"\n",
    "        assert x.is_cuda and weight.is_cuda, \"Expected CUDA tensors\"\n",
    "        assert x.is_contiguous(), \"Our pointer arithmetic will assume contiguous x\"\n",
    "\n",
    "        ctx.D_TILE_SIZE = 32# triton.next_power_of_2(D) // 16 # Roughly 16 loops through the embedding dimension\n",
    "        print(ctx.D_TILE_SIZE)\n",
    "        ctx.ROWS_TILE_SIZE = 16 # Each thread processes 16 batch elements at a time\n",
    "        ctx.input_shape = input_shape\n",
    "\n",
    "        # Need to initialize empty result tensor. Note that these elements are not necessarily 0!\n",
    "        y = torch.empty(output_dims, device=x.device)\n",
    "\n",
    "        # Launch our kernel with n instances in our 1D grid.\n",
    "        n_rows = y.numel()\n",
    "        weighted_sum_fwd[(triton.cdiv(n_rows, ctx.ROWS_TILE_SIZE),)](\n",
    "            x, weight,\n",
    "            y,\n",
    "            x.stride(0), x.stride(1),\n",
    "            weight.stride(0),\n",
    "            y.stride(0),\n",
    "            ROWS=n_rows, D=D,\n",
    "            ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE, D_TILE_SIZE=ctx.D_TILE_SIZE,\n",
    "        )\n",
    "\n",
    "        return y.view(input_shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94f133",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_sum(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:\n",
    "    return WeightedSumFunc.apply(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3b23a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x = torch.randn(2, 3, 4, device=\"cuda\", requires_grad=False)  # batch_size=2, seq_len=3, dim=4\n",
    "weight = torch.randn(4, device=\"cuda\", requires_grad=False)  # dim=4\n",
    "\n",
    "y = weighted_sum(x, weight)  # shape -> (2, 3)\n",
    "print(\"Output:\", y)\n",
    "\n",
    "# Можно делать backward\n",
    "loss = y.sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10329487",
   "metadata": {},
   "source": [
    "# Sum two digits kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127deb37",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def sum_kernel(\n",
    "    arr1_ptr,\n",
    "    arr2_ptr,\n",
    "    output_ptr,\n",
    "    N, BLOCK_SIZE :tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < N\n",
    "\n",
    "    arr1 = tl.load(arr1_ptr + offsets, mask=mask)\n",
    "    arr2 = tl.load(arr2_ptr + offsets, mask=mask)\n",
    "\n",
    "    output = arr1 + arr2\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cc422",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add(arr1: torch.Tensor, arr2: torch.Tensor):\n",
    "    output = torch.empty_like(arr1)\n",
    "    N = output.numel()\n",
    "        \n",
    "    grid = lambda meta: (triton.cdiv(N, 1024),)\n",
    "    \n",
    "    sum_kernel[grid](arr1.contiguous(), arr2.contiguous(), output, N, BLOCK_SIZE=1024)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db5b78",
   "metadata": {},
   "source": [
    "# ReLU Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd60712",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def relu_kernel(\n",
    "    input_ptr, output_ptr,\n",
    "    N, BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    mask = offsets < N\n",
    "\n",
    "    input_t = tl.load(input_ptr + offsets, mask=mask)\n",
    "    # output = tl.maximum(input_t, 0)\n",
    "    output = tl.where(input_t>0, input_t, 0)\n",
    "\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4750e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def relu(x: torch.Tensor):\n",
    "    output = torch.empty_like(x)\n",
    "    N = output.numel()\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(N, 1024),)\n",
    "    relu_kernel[grid](x.contiguous(), output, N, BLOCK_SIZE=1024)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e7910",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_relu():\n",
    "    test_cases = [\n",
    "        torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32, device=\"cuda\"),            \n",
    "        torch.tensor([-1.0, -2.0, -3.0], dtype=torch.float32, device=\"cuda\"),                \n",
    "        torch.tensor([-1.0, 0.0, 1.0], dtype=torch.float32, device=\"cuda\"),                 \n",
    "        torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32, device=\"cuda\"),                    \n",
    "        torch.randn(1024, dtype=torch.float32, device=\"cuda\"),                                \n",
    "    ]\n",
    "\n",
    "    for i, x in enumerate(test_cases):\n",
    "        expected = F.relu(x)\n",
    "        result = relu(x)\n",
    "        if not torch.allclose(result, expected, atol=1e-6):\n",
    "            print(f\"Test case {i} failed\")\n",
    "            print(\"Input:    \", x)\n",
    "            print(\"Expected: \", expected)\n",
    "            print(\"Result:   \", result)\n",
    "        else:\n",
    "            print(f\"Test case {i} passed\")\n",
    "\n",
    "test_relu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d444006",
   "metadata": {},
   "source": [
    "# Comparision Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4c7bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def comparison_kernel(\n",
    "    a_ptr, b_ptr, output_ptr, N, BLOCK_SIZE \n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < N\n",
    "\n",
    "    a = tl.load(a_ptr + offsets, mask)\n",
    "    b = tl.load(b_ptr + offsets, mask)\n",
    "\n",
    "    output = a == b\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac8971",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def comparison(x: torch.Tensor, y: torch.Tensor):\n",
    "    output = torch.empty_like(x, dtype=torch.int)\n",
    "    N = output.numel()\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(N, 1024),)\n",
    "    comparison_kernel[grid](x.contiguous(), y.contiguous(), output, N, BLOCK_SIZE=1024)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888b66",
   "metadata": {},
   "source": [
    "# Softmax 1-d Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61085c1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def softmax_kernel(\n",
    "    x_ptr, output_ptr, N, BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < N\n",
    "\n",
    "    x = tl.load(x_ptr + offsets, mask)\n",
    "    x = tl.where(mask, x, -float(\"inf\"))\n",
    "\n",
    "    max_x = tl.max(x, axis=0)\n",
    "    exp_x = tl.exp(x - max_x)\n",
    "    sum_exp = tl.sum(exp_x, axis=0)\n",
    "    output = exp_x / sum_exp\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20222be3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def soft(x: torch.Tensor):\n",
    "    output = torch.empty_like(x)\n",
    "    N = output.numel()\n",
    "\n",
    "    grid = lambda meta: (triton.cdiv(N, 1024),)\n",
    "    softmax_kernel[grid](x.contiguous(), output, N, BLOCK_SIZE=1024)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d180a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_softmax():\n",
    "    x = torch.tensor([1.0, 2.0, 3.0, 4.0], device='cuda')\n",
    "    print(\"Input:\", x)\n",
    "    \n",
    "    output = soft(x)\n",
    "    print(\"Softmax Output:\", output)\n",
    "\n",
    "    expected = torch.softmax(x, dim=0)\n",
    "    print(\"Expected:\", expected)\n",
    "    print(\"Test 1 passed:\", torch.allclose(output, expected, atol=1e-5))\n",
    "\n",
    "    x2 = torch.randn(1024, device='cuda')\n",
    "    output2 = soft(x2)\n",
    "    expected2 = torch.softmax(x2, dim=0)\n",
    "    print(\"Test 2 passed:\", torch.allclose(output2, expected2, atol=1e-5))\n",
    "\n",
    "    x3 = torch.randn(4096, device='cuda')\n",
    "    output3 = soft(x3)\n",
    "    expected3 = torch.softmax(x3, dim=0)\n",
    "    print(\"Test 3 passed:\", torch.allclose(output3, expected3, atol=1e-5))\n",
    "\n",
    "test_softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108d2db",
   "metadata": {},
   "source": [
    "# Softmax n-d Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91172a6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def softmax_nd_kernel(\n",
    "    input_ptr, output_ptr,\n",
    "    input_row_stride, input_col_stride,\n",
    "    output_row_stride, output_col_stride,\n",
    "    N, BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "\n",
    "    row_start_ptr = input_ptr + pid * input_row_stride\n",
    "\n",
    "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    mask = col_offsets < N\n",
    "\n",
    "    input_ptrs = row_start_ptr + col_offsets * input_col_stride\n",
    "    x = tl.load(input_ptrs, mask=mask, other=-float('inf'))\n",
    "\n",
    "    max_x = tl.max(x, axis=0)\n",
    "    x_exp = tl.exp(x - max_x)\n",
    "    sum_exp = tl.sum(x_exp, axis=0)\n",
    "    softmax_output = x_exp / sum_exp\n",
    "\n",
    "    output_row_start_ptr = output_ptr + pid * output_row_stride\n",
    "    output_ptrs = output_row_start_ptr + col_offsets * output_col_stride\n",
    "    tl.store(output_ptrs, softmax_output, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a95ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def soft_nd(x: torch.Tensor, BLOCK_SIZE=1024):\n",
    "    original_shape = x.shape\n",
    "    N = x.shape[-1]\n",
    "    num_rows = x.numel() // N  \n",
    "\n",
    "    x_2d = rearrange(x, \"... d -> (...) d\")\n",
    "    output = torch.empty_like(x_2d)\n",
    "\n",
    "    input_stride_row = x_2d.stride(0) \n",
    "    input_stride_col = x_2d.stride(1) \n",
    "\n",
    "    output_stride_row = output.stride(0)\n",
    "    output_stride_col = output.stride(1)\n",
    "\n",
    "    # grid = (triton.cdiv(num_rows, BLOCK_SIZE), )\n",
    "    grid = ((num_rows + BLOCK_SIZE - 1) // BLOCK_SIZE, )\n",
    "\n",
    "    softmax_nd_kernel[grid](\n",
    "        x_2d,\n",
    "        output,\n",
    "        input_stride_row,\n",
    "        input_stride_col,\n",
    "        output_stride_row,\n",
    "        output_stride_col,\n",
    "        N,\n",
    "        BLOCK_SIZE=BLOCK_SIZE,\n",
    "    )\n",
    "\n",
    "    return output.view(*original_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc49896",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_soft_nd():\n",
    "    atol = 1e-5\n",
    "\n",
    "    # 1D\n",
    "    x1 = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "    out1 = soft_nd(x1)\n",
    "    expected1 = torch.softmax(x1, dim=-1)\n",
    "    print(\"1D test:\", torch.allclose(out1, expected1, atol=atol))\n",
    "\n",
    "    # 2D\n",
    "    x2 = torch.randn(4, 8, device='cuda')\n",
    "    out2 = soft_nd(x2)\n",
    "    expected2 = torch.softmax(x2, dim=-1)\n",
    "    print(\"2D test:\", torch.allclose(out2, expected2, atol=atol))\n",
    "    print(out2, expected2)\n",
    "\n",
    "\n",
    "    # 3D\n",
    "    x3 = torch.randn(3, 5, 8, device='cuda')\n",
    "    out3 = soft_nd(x3)\n",
    "    expected3 = torch.softmax(x3, dim=-1)\n",
    "    print(\"3D test:\", torch.allclose(out3, expected3, atol=atol))\n",
    "\n",
    "    # 4D\n",
    "    x4 = torch.randn(2, 3, 4, 8, device='cuda')\n",
    "    out4 = soft_nd(x4)\n",
    "    expected4 = torch.softmax(x4, dim=-1)\n",
    "    print(\"4D test:\", torch.allclose(out4, expected4, atol=atol))\n",
    "\n",
    "    # Batched edge case\n",
    "    x5 = torch.randn(10, 1024, device='cuda')\n",
    "    out5 = soft_nd(x5)\n",
    "    expected5 = torch.softmax(x5, dim=-1)\n",
    "    print(\"Large 2D test:\", torch.allclose(out5, expected5, atol=atol))\n",
    "\n",
    "test_soft_nd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdc9a8",
   "metadata": {},
   "source": [
    "# Online Softmax Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490bb8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def online_softmax_kernel(\n",
    "    input_ptr, output_ptr,\n",
    "    input_row_stride, input_col_stride,\n",
    "    output_row_stride, output_col_stride,\n",
    "    N, BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    input_start_ptr = input_ptr + pid * input_row_stride\n",
    "\n",
    "    mask = col_offsets < N\n",
    "\n",
    "    M_old = -float('inf')\n",
    "    L_old = 0.0\n",
    "\n",
    "    num_blocks = (N + BLOCK_SIZE - 1) // BLOCK_SIZE\n",
    "\n",
    "    for block_id in range(num_blocks):\n",
    "        col_ids = block_id * BLOCK_SIZE + col_offsets\n",
    "        mask = col_ids < N\n",
    "\n",
    "        input_block_ptr = input_start_ptr + col_ids * input_col_stride\n",
    "        x_block = tl.load(input_block_ptr, mask=mask, other=-float('inf'))\n",
    "        local_max = tl.max(x_block)\n",
    "\n",
    "        M_new = tl.maximum(local_max, M_old)\n",
    "        scale = tl.exp(M_old - M_new)\n",
    "        exp_diff = tl.exp(x_block - M_new)\n",
    "        L_new = tl.where(M_new > M_old,\n",
    "                        L_old * scale + tl.sum(exp_diff),\n",
    "                        L_old + tl.sum(exp_diff))\n",
    "        \n",
    "        M_old = M_new\n",
    "        L_old = L_new\n",
    "        \n",
    "    for block_id in range(num_blocks):\n",
    "        col_ids = block_id * BLOCK_SIZE + col_offsets\n",
    "        mask = col_ids < N\n",
    "\n",
    "        input_block_ptr = input_start_ptr + col_ids * input_col_stride\n",
    "        x_block = tl.load(input_block_ptr, mask=mask, other=-float('inf'))\n",
    "\n",
    "        shifted = x_block - M_old\n",
    "        exp_shifted = tl.exp(shifted)\n",
    "        softmax_block = exp_shifted / L_old\n",
    "        output_block_ptr = output_ptr + pid * output_row_stride + col_ids * output_col_stride\n",
    "        tl.store(output_block_ptr, softmax_block, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743f73c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def online_softmax_pt(input: torch.Tensor, block_size=1024):\n",
    "\n",
    "    assert input.dim() == 2, \"input tensor should be 2D\"\n",
    "    assert input.device.type == \"cuda\", \"input tensor should be on CUDA\"\n",
    "\n",
    "    input = input.contiguous()\n",
    "    B, N = input.size()\n",
    "    # original_shape = input.shape\n",
    "\n",
    "    output = torch.empty_like(input)\n",
    "\n",
    "    grid = (B,)\n",
    "\n",
    "    online_softmax_kernel[grid](\n",
    "        input,\n",
    "        output,\n",
    "        input.stride(0), input.stride(1),\n",
    "        output.stride(0), output.stride(1),\n",
    "        N,\n",
    "        # BLOCK_SIZE=block_size,\n",
    "    )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2708173",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "B, N = 4, 128\n",
    "x = torch.randn(B, N, device='cuda', dtype=torch.float32)\n",
    "\n",
    "# Triton softmax\n",
    "out_triton = online_softmax_pt(x)\n",
    "\n",
    "# PyTorch softmax\n",
    "out_torch = F.softmax(x, dim=-1)\n",
    "\n",
    "max_diff = (out_triton - out_torch).abs().max().item()\n",
    "print(f\"Max difference: {max_diff:.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b639fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2cde6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
